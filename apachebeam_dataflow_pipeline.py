# -*- coding: utf-8 -*-
"""Apachebeam dataflow pipeline

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rB0LbAkrPQwji3fmbgOde168caLPPRwn
"""

from __future__ import absolute_import
import argparse
import logging
import re
import sys
import six
import random
import os
import time
import logging
import traceback
import json
from detoxify import Detoxify
import apache_beam as beam
from apache_beam.options.pipeline_options import PipelineOptions
from apache_beam.options.pipeline_options import SetupOptions
from apache_beam.io.gcp.internal.clients import bigquery
from google.cloud import language
from google.cloud import storage


class DetoxDoFn(beam.DoFn):
  def __init__(self):
    beam.DoFn.__init__(self)
  def process(self,element):
    """Returns an iterator over the words of this element.
    """
    """Detoxifies the provided text."""
    from detoxify import Detoxify
    import logging
    import json
    try:
        input_text=element['text']
        results = {}
        results = Detoxify('original').predict(input_text)
        results['comment_id']=str(element['comment_id'])
        detox_results = {'comment_id': str(element['comment_id']) , 'toxicity': float(results['toxicity']), 'severe_toxicity': float(results['severe_toxicity']), 'obscene': float(results['obscene']), 'threat': float(results['threat']), 'insult': float(results['insult']), 'identity_hate': float(results['identity_hate'])}            
    except Exception as e:
        logging.exception("error in process")  
    return [detox_results]

def run(argv=None, save_main_session=False):
    PROJECT_ID='hatespeech-2019'
    SCHEMA='comment_id:STRING, toxicity:FLOAT, severe_toxicity:FLOAT, obscene:FLOAT, threat:FLOAT, insult:FLOAT, identity_hate:FLOAT'
    pipeline_options = PipelineOptions(
        flags=argv,
        runner='DataflowRunner',
        project='hatespeech-2019',
        job_name='dataflowtrial',
        requirements_file='requirements.txt',
        temp_location='gs://detoxify/',
        region='us-west1')
  # We use the save_main_session option because one or more DoFn's in this
  # workflow rely on global context (e.g., a module imported at module level).
    pipeline_options.view_as(SetupOptions).save_main_session = save_main_session
    p = beam.Pipeline(options=pipeline_options)

  # Read the big query table into a PCollection.
    query_string = 'SELECT comment_id, text, all_hs FROM `hatespeech-2019.Final_Dataset.Channel_Videos_Comments_Merged` where all_hs=1 LIMIT 20' 
    detox_data = (
        p
        | 'QueryTableStdSQL' >> beam.io.Read(beam.io.BigQuerySource(
            query=query_string,
            use_standard_sql=True))
        | 'detoxify' >> beam.ParDo(DetoxDoFn()))
    write_data =  detox_data  | 'writetobigquery'>> beam.io.WriteToBigQuery(table='Toxicity_results',dataset='Final_Dataset',
                                                        project='hatespeech-2019',schema= SCHEMA, 
                                                    write_disposition=beam.io.BigQueryDisposition.WRITE_APPEND)
    result = p.run()
    result.wait_until_finish()

if __name__ == '__main__':
  logging.getLogger().setLevel(logging.INFO)
  run()

# apache-beam
# https://download.pytorch.org/whl/cpu/torch-1.8.1%2Bcpu-cp37-cp37m-linux_x86_64.whl
# detoxify==0.2.2

